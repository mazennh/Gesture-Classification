{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4275761,"sourceType":"datasetVersion","datasetId":2466069}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Configuration & Imports","metadata":{}},{"cell_type":"code","source":"# 1. Remove old folder if it exists\n!rm -rf YourRepoName\n\n# 2. Clone your code\n!git clone https://github.com/mazennh/Gesture-Classification.git\n\n# 3. Install dependencies\n!pip install -r /kaggle/working/Gesture-Classification/requirements.txt --quiet\n\n# 4. Allow Python to find your files\nimport sys\nimport os\nsys.path.append(os.path.abspath(\"/kaggle/working/Gesture-Classification\"))\n\n# 5. Auto-reload (Optional: helps if you edit code and git pull)\n%load_ext autoreload\n%autoreload 2\n\nprint(\"Setup Complete! Your custom modules are ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T18:11:46.941921Z","iopub.execute_input":"2025-12-14T18:11:46.942202Z","iopub.status.idle":"2025-12-14T18:11:54.944724Z","shell.execute_reply.started":"2025-12-14T18:11:46.942179Z","shell.execute_reply":"2025-12-14T18:11:54.943872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport subprocess\nfrom torchinfo import summary\nimport warnings\nfrom torch.optim.lr_scheduler import StepLR\nfrom pyngrok import ngrok\nimport data_utils\nimport model_utils\nimport train_utils\nimport vis_utils\n\nwarnings.filterwarnings(\"ignore\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T00:47:48.554945Z","iopub.execute_input":"2025-12-14T00:47:48.55517Z","iopub.status.idle":"2025-12-14T00:48:17.021786Z","shell.execute_reply.started":"2025-12-14T00:47:48.555147Z","shell.execute_reply":"2025-12-14T00:48:17.021187Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Pipeline Construction","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Dataset Filtering & Splitting","metadata":{}},{"cell_type":"code","source":"data_utils.filter_data(input_path = '/kaggle/input/hagrid-classification-512p/hagrid-classification-512p',\n           output_path = '/kaggle/working/filtered_data',\n           split_path = '/kaggle/working/splited_data',\n           classes_list = [\"stop\", \"dislike\", \"like\",\n                           \"peace\", \"peace_inverted\", \"ok\",\n                           \"call\", \"mute\", \"stop_inverted\"],\n           split_ratio = (0.8,0.1,0.1),\n           seed = 42\n          )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T00:48:17.022636Z","iopub.execute_input":"2025-12-14T00:48:17.023326Z","iopub.status.idle":"2025-12-14T01:15:40.936093Z","shell.execute_reply.started":"2025-12-14T00:48:17.023291Z","shell.execute_reply":"2025-12-14T01:15:40.935172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2 Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"markdown","source":"### 2.2.1 Class Distribution Analysis\n\nthe dataset is well-balanced across all target classes. Since there is no significant class imbalance, no oversampling or class-weighting techniques are required","metadata":{}},{"cell_type":"code","source":"data_utils.class_distribution(root_path = '/kaggle/working/filtered_data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:40.937039Z","iopub.execute_input":"2025-12-14T01:15:40.937279Z","iopub.status.idle":"2025-12-14T01:15:41.136279Z","shell.execute_reply.started":"2025-12-14T01:15:40.93726Z","shell.execute_reply":"2025-12-14T01:15:41.135487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_utils.class_distribution(root_path = '/kaggle/working/splited_data/train')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:41.138301Z","iopub.execute_input":"2025-12-14T01:15:41.138561Z","iopub.status.idle":"2025-12-14T01:15:41.311662Z","shell.execute_reply.started":"2025-12-14T01:15:41.13854Z","shell.execute_reply":"2025-12-14T01:15:41.31093Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_utils.class_distribution(root_path = '/kaggle/working/splited_data/val')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:41.31246Z","iopub.execute_input":"2025-12-14T01:15:41.312678Z","iopub.status.idle":"2025-12-14T01:15:41.391439Z","shell.execute_reply.started":"2025-12-14T01:15:41.31266Z","shell.execute_reply":"2025-12-14T01:15:41.390887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_utils.class_distribution(root_path = '/kaggle/working/splited_data/test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:41.392173Z","iopub.execute_input":"2025-12-14T01:15:41.392458Z","iopub.status.idle":"2025-12-14T01:15:41.469911Z","shell.execute_reply.started":"2025-12-14T01:15:41.39244Z","shell.execute_reply":"2025-12-14T01:15:41.469319Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2.2 Sample Visualization & Resolution Check\nAnalysis of random samples indicates that most images have a resolution of **512×512**. However, our target architectures **(VGG16, ResNet, InceptionV1, ViT)** generally are optimized for input dimensions of **224×224**.","metadata":{}},{"cell_type":"code","source":"vis_utils.visualize_random_samples(root_path = \"/kaggle/working/filtered_data\",\n                                   n_samples=10,\n                                   cols = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:41.470578Z","iopub.execute_input":"2025-12-14T01:15:41.470863Z","iopub.status.idle":"2025-12-14T01:15:43.169131Z","shell.execute_reply.started":"2025-12-14T01:15:41.470844Z","shell.execute_reply":"2025-12-14T01:15:43.16819Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 Image Augmentation & Preprocessing\n\n### Train\n* RandomResizedCrop **(Resize -> 224,224)**\n* RandomHorizontalFlip\n* RandomRotation **(5° to 15°)**\n* Brightness/Contrast **(ColorJitter)**\n* ToTensor\n* Normalize\n\n### Test & Val\n\n* Turn data into **tensors**\n* Normalization\n* Resize **(224,224)** ","metadata":{}},{"cell_type":"code","source":"dls = data_utils.create_dataloaders(\n    data_dir=\"/kaggle/working/splited_data\",\n    batch_size=32,\n    img_size=224\n)\n\ntrain_dataloader, val_dataloader, test_dataloader, train_dataset, class_names, class_dict = dls\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:43.169875Z","iopub.execute_input":"2025-12-14T01:15:43.170149Z","iopub.status.idle":"2025-12-14T01:15:45.187004Z","shell.execute_reply.started":"2025-12-14T01:15:43.170124Z","shell.execute_reply":"2025-12-14T01:15:45.18603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.4 Data Verification\n\n#### Sanity Check\n\nBefore feeding data into the model, we perform a final sanity check. We retrieve a single batch from the DataLoader, reverse the normalization, and visualize the images. This ensures that our augmentation pipeline is functioning correctly and that labels match the image content.","metadata":{}},{"cell_type":"code","source":"img, _ = next(iter(train_dataloader))\nimg.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:45.188184Z","iopub.execute_input":"2025-12-14T01:15:45.188579Z","iopub.status.idle":"2025-12-14T01:15:46.383598Z","shell.execute_reply.started":"2025-12-14T01:15:45.188544Z","shell.execute_reply":"2025-12-14T01:15:46.382727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis_utils.data_verification(dataset = train_dataset,\n                            class_names = class_names,\n                            n_rows=3,\n                            n_cols=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:46.384825Z","iopub.execute_input":"2025-12-14T01:15:46.385293Z","iopub.status.idle":"2025-12-14T01:15:47.471806Z","shell.execute_reply.started":"2025-12-14T01:15:46.385268Z","shell.execute_reply":"2025-12-14T01:15:47.470903Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Making Model","metadata":{}},{"cell_type":"code","source":"model, architecture_name = model_utils.get_model(num_classes=len(class_names),\n                                                 model_name='inception v1',\n                                                 device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:47.472714Z","iopub.execute_input":"2025-12-14T01:15:47.473104Z","iopub.status.idle":"2025-12-14T01:15:51.172639Z","shell.execute_reply.started":"2025-12-14T01:15:47.473074Z","shell.execute_reply":"2025-12-14T01:15:51.171772Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 Model Summary","metadata":{}},{"cell_type":"code","source":"img, _ = next(iter(train_dataloader))\nimg.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:51.173775Z","iopub.execute_input":"2025-12-14T01:15:51.174103Z","iopub.status.idle":"2025-12-14T01:15:55.780046Z","shell.execute_reply.started":"2025-12-14T01:15:51.174076Z","shell.execute_reply":"2025-12-14T01:15:55.779301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"summary(model,input_size=(img.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:55.783182Z","iopub.execute_input":"2025-12-14T01:15:55.783411Z","iopub.status.idle":"2025-12-14T01:15:57.148898Z","shell.execute_reply.started":"2025-12-14T01:15:55.783391Z","shell.execute_reply":"2025-12-14T01:15:57.148273Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4 Model Training","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Loss Function & Optimizer","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:57.149607Z","iopub.execute_input":"2025-12-14T01:15:57.149857Z","iopub.status.idle":"2025-12-14T01:15:57.218099Z","shell.execute_reply.started":"2025-12-14T01:15:57.149839Z","shell.execute_reply":"2025-12-14T01:15:57.217409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 Model Training","metadata":{}},{"cell_type":"code","source":"model_train=train_utils.train(model=model,\n                              train_dataloader=train_dataloader,\n                              val_dataloader=val_dataloader,\n                              optimizer=optimizer,\n                              loss_fn=loss_fn,\n                              num_classes = len(class_names),\n                              best_model = architecture_name,\n                              scheduler=scheduler,\n                              device=device,\n                              patience=5,\n                              experiment_name = architecture_name,\n                              epochs=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T01:15:57.218855Z","iopub.execute_input":"2025-12-14T01:15:57.219049Z","iopub.status.idle":"2025-12-14T12:47:38.737858Z","shell.execute_reply.started":"2025-12-14T01:15:57.219033Z","shell.execute_reply":"2025-12-14T12:47:38.736677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}